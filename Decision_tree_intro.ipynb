{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision tree intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjkt7yF9nsgcJqu+FIrtCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alireza414/Decision-Tree/blob/main/Decision_tree_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBmmWEulVzs5"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Create Class a with mean=0, stddev=1\n",
        "a = np.random.normal(loc=0,scale=1,size=(100,2))\n",
        "# Create Class a with mean=10, stddev=1\n",
        "b = np.random.normal(loc=10,scale=1,size=(100,2))\n",
        "print('1st',a,b)\n",
        "# Add class a label\n",
        "a = np.concatenate((a,np.zeros((100,1))),axis=1)\n",
        "# Add class b label\n",
        "b = np.concatenate((b,np.zeros((100,1))+1),axis=1)\n",
        "# c is all data together\n",
        "c = np.concatenate((a,b))\n",
        "# shuffle data\n",
        "np.random.shuffle(c)\n",
        "# make into dataframe for people that give 75s on exams\n",
        "df = pd.DataFrame(c,columns=['x','y','labels'])\n",
        "display(df)\n",
        "feature_cols = ['x','y']\n",
        "X = df[feature_cols]\n",
        "y = df['labels']\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(a[:,0],a[:,1])\n",
        "plt.scatter(b[:,0],b[:,1])\n",
        "\n",
        "plt.figure(figsize = [15,10])\n",
        "sns.heatmap(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification tree **"
      ],
      "metadata": {
        "id": "5wtTk0fg1U55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Visualize Decision Tree"
      ],
      "metadata": {
        "id": "J61DvjjyV_Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Visualizing the decision tree*"
      ],
      "metadata": {
        "id": "W5I26neJ7dhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "fig = plt.figure(figsize=(30,30))\n",
        "_ = tree.plot_tree(clf, fontsize=9)"
      ],
      "metadata": {
        "id": "_EtEH3Y-7X0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Regression tree*"
      ],
      "metadata": {
        "id": "XhLXP2Ux1I12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree classifer object\n",
        "Rgr = DecisionTreeRegressor()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "Rgr = Rgr.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = Rgr.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "YKQ4qs0iuvJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *More example using wine dataset*"
      ],
      "metadata": {
        "id": "k254GIDv1nOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',sep=';')\n",
        "# X = dataset.data; y = dataset.target\n",
        "# Take a look\n",
        "print(df.head(5))\n",
        "# Data dimensionality (rows, colums)\n",
        "print(df.shape)\n",
        "# Data distributing\n",
        "# df.info()\n",
        "sns.scatterplot(df['alcohol'], df['chlorides'], hue= df['quality'], s=50)\n",
        "\n"
      ],
      "metadata": {
        "id": "jgrBt22-mAT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Classification Tree*"
      ],
      "metadata": {
        "id": "P_HnTjmE18b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']# Train and Test splitting of data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Report: \\n\", metrics.classification_report(y_test, y_pred))\n",
        "print(\"Precision = TP/TP+FP \\n\", \"Recall = TP/TP+FN \\n\", \"f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \\n\", \"Support = Actual number of occurance \\n\", )\n",
        "print(\"Confusion Matrix: \\n\",metrics.confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "9zAsi7lAWK5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Regression tree*"
      ],
      "metadata": {
        "id": "GGcs3LSc2Uav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']# Train and Test splitting of data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "Rgr = DecisionTreeRegressor()\n",
        "Rgr.fit(X_train, y_train)\n",
        "print(Rgr)\n",
        "\n",
        "y_pred = Rgr.predict(X_test)\n",
        "print(y_pred.shape)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Report: \\n\", metrics.classification_report(y_test, y_pred))\n",
        "print(\"Precision = TP/TP+FP \\n\", \"Recall = TP/TP+FN \\n\", \"f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \\n\", \"Support = Actual number of occurance \\n\", )\n",
        "print(\"Confusion Matrix: \\n\",metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG9Up6gr2CQ_",
        "outputId": "ab1aed50-920a-4a78-b6d3-8506c6e4b2be"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeRegressor()\n",
            "(400,)\n",
            "Accuracy: 0.55\n",
            "Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.61      0.61      0.61       163\n",
            "           6       0.59      0.54      0.57       167\n",
            "           7       0.52      0.59      0.55        49\n",
            "           8       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.55       400\n",
            "   macro avg       0.29      0.29      0.29       400\n",
            "weighted avg       0.56      0.55      0.55       400\n",
            "\n",
            "Precision = TP/TP+FP \n",
            " Recall = TP/TP+FN \n",
            " f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \n",
            " Support = Actual number of occurance \n",
            "\n",
            "Confusion Matrix: \n",
            " [[  0   0   1   0   0   0]\n",
            " [  1   0  10   3   1   0]\n",
            " [  0  16 100  40   6   1]\n",
            " [  0   5  51  91  19   1]\n",
            " [  0   0   1  17  29   2]\n",
            " [  0   0   0   4   1   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "fig = plt.figure(figsize=(30,30))\n",
        "_ = tree.plot_tree(Rgr, fontsize=9)\n"
      ],
      "metadata": {
        "id": "szHBkRaB2_LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import ensemble\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.ensemble import (\n",
        "    BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        ")\n",
        "\n",
        "model = ensemble.BaggingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test) \n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Report: \\n\", metrics.classification_report(y_test, y_pred))\n",
        "print(\"Precision = TP/TP+FP \\n\", \"Recall = TP/TP+FN \\n\", \"f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \\n\", \"Support = Actual number of occurance \\n\", )\n",
        "print(\"Confusion Matrix: \\n\",metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "nPToMak93DzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ensemble.ExtraTreesClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test) \n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Report: \\n\", metrics.classification_report(y_test, y_pred))\n",
        "print(\"Precision = TP/TP+FP \\n\", \"Recall = TP/TP+FN \\n\", \"f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \\n\", \"Support = Actual number of occurance \\n\", )\n",
        "print(\"Confusion Matrix: \\n\",metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "HXa4AcuMPyVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ensemble.RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "y_pred = model.predict(X_test) \n",
        "\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Report: \\n\", metrics.classification_report(y_test, y_pred))\n",
        "print(\"Precision = TP/TP+FP \\n\", \"Recall = TP/TP+FN \\n\", \"f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \\n\", \"Support = Actual number of occurance \\n\", )\n",
        "print(\"Confusion Matrix: \\n\",metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N2P4GGnUlp3",
        "outputId": "f91edb65-30ba-4b35-813c-ccb347937907"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier()\n",
            "Accuracy: 0.7225\n",
            "Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.75      0.82      0.79       163\n",
            "           6       0.71      0.77      0.74       167\n",
            "           7       0.64      0.55      0.59        49\n",
            "           8       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.72       400\n",
            "   macro avg       0.35      0.36      0.35       400\n",
            "weighted avg       0.68      0.72      0.70       400\n",
            "\n",
            "Precision = TP/TP+FP \n",
            " Recall = TP/TP+FN \n",
            " f1 score = F1 Score = 2*(Recall * Precision) / (Recall + Precision) \n",
            " Support = Actual number of occurance \n",
            "\n",
            "Confusion Matrix: \n",
            " [[  0   0   1   0   0   0]\n",
            " [  0   0  10   5   0   0]\n",
            " [  0   0 134  26   3   0]\n",
            " [  0   0  31 128   8   0]\n",
            " [  0   0   2  20  27   0]\n",
            " [  0   0   0   1   4   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}